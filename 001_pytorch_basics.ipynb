{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "001_pytorch_basics.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "lZWRC9x8DUSh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 001_pytorch_basics"
      ]
    },
    {
      "metadata": {
        "id": "QjQ93O8DBVLa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Essential imports\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ytoHJtf4BVL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "1319f8af-9660-4127-b275-4dd009263296"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 25kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x59ad2000 @  0x7f0e704f42a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IBgN1PyQbItd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "84622482-fd40-4bf2-b1bf-f4b68fec6bdb"
      },
      "cell_type": "code",
      "source": [
        "# torch.tensor\n",
        "t1 = torch.tensor([1., 2., 3., 4., 5.], dtype=torch.float64)\n",
        "t2 = torch.tensor([5., 6., 7., 8., 9.], dtype=torch.float16)\n",
        "\n",
        "print ('t1: ', t1)\n",
        "print ('t2: ', t2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t1:  tensor([1., 2., 3., 4., 5.])\n",
            "t2:  tensor([5., 6., 7., 8., 9.], dtype=torch.float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "53cm8L49BhmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cc1ca275-0ec0-4aa5-e66c-b35f1853cb6f"
      },
      "cell_type": "code",
      "source": [
        "# torch.is_tensor \n",
        "t1 = torch.tensor([1, 2, 3, 4, 5])\n",
        "t2 = [1, 2, 3, 4, 5]\n",
        "\n",
        "print (torch.is_tensor(t1))\n",
        "print (torch.is_tensor(t2))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u0SCF1hsC6OU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "49ea966b-5c16-48f9-9070-37aaa23b1749"
      },
      "cell_type": "code",
      "source": [
        "# torch,is_storage\n",
        "s1 = torch.FloatStorage(128)\n",
        "s2 = np.float(128)\n",
        "\n",
        "print (torch.is_storage(s1))\n",
        "print (torch.is_storage(s2))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LFIFdrM5EKzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7ba3f20f-8736-4251-e488-4e28f90a9ad2"
      },
      "cell_type": "code",
      "source": [
        "# torch.set_default_type\n",
        "# Sets the default torch.tensor() type to a floating point tensor type\n",
        "\n",
        "t1 = torch.tensor([1., 2., 3])\n",
        "\n",
        "print ('The default type is: ', t1.dtype)\n",
        "\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "t2 = torch.tensor([1., 2., 3])\n",
        "\n",
        "print ('Now the default dtype is: ', t2.dtype)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The default type is:  torch.float32\n",
            "Now the default dtype is:  torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "riVnovFNEnxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4ba7134d-6b76-44f6-c307-05a99278675a"
      },
      "cell_type": "code",
      "source": [
        "# torch.get_default_dtype\n",
        "# Returns the current default floating point\n",
        "\n",
        "print ('The default dtype is: ', torch.get_default_dtype())\n",
        "\n",
        "torch.set_default_dtype(torch.float16)\n",
        "print ('The default dtype now is: ', torch.get_default_dtype())\n",
        "\n",
        "torch.set_default_dtype(torch.float64)\n",
        "print ('The default dtype now is: ', torch.get_default_dtype())\n",
        "\n",
        "# Cannot set the default type to non-float type\n",
        "#torch.set_default_dtype(torch.int16)\n",
        "#print ('The default dtype now is: ', torch.get_default_dtype())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The default dtype is:  torch.float32\n",
            "The default dtype now is:  torch.float16\n",
            "The default dtype now is:  torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XsNJPkNHGIhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cd3552b6-f30e-4102-b5a0-5deb941e85f8"
      },
      "cell_type": "code",
      "source": [
        "# torch.set_default_tensor_type\n",
        "# Sets the default torch.tensor() type to a floating point tensor type\n",
        "\n",
        "print ('The default dtype is: ', torch.get_default_dtype())\n",
        "\n",
        "torch.set_default_tensor_type(torch.FloatTensor)\n",
        "print ('The default dtype now is: ', torch.get_default_dtype())\n",
        "\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "print ('The default dtype now is: ', torch.get_default_dtype())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The default dtype is:  torch.float64\n",
            "The default dtype now is:  torch.float32\n",
            "The default dtype now is:  torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VIIJiXEMJ0fm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "09d509f2-a77a-4719-ce7c-b1e2ab8f2f78"
      },
      "cell_type": "code",
      "source": [
        "# torch.numel\n",
        "# Returns the total number of elements in the tensor\n",
        "\n",
        "t1 = torch.randn(4, 5)\n",
        "print ('The number of elements in t1: ', t1.numel())\n",
        "\n",
        "t2 = torch.randn(5, 4, 2)\n",
        "print ('The number of elements in t2: ', t2.numel())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of elements in t1:  20\n",
            "The number of elements in t2:  40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YP_8_PKRMMQE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# torch.set_printoptions\n",
        "# Helps set the options for printing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_TIJ4PzTNxr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e4f886c5-5ccd-4b75-864a-d46bd64b38b5"
      },
      "cell_type": "code",
      "source": [
        "# torch.set_flush_denormal\n",
        "# Disables denormal floating numbers on CPU\n",
        "\n",
        "torch.set_flush_denormal(True)\n",
        "t1 = torch.tensor([1e-323, 1e-235, 1e-121], dtype=torch.float64)\n",
        "print ('t1: ', t1)\n",
        "\n",
        "torch.set_flush_denormal(False)\n",
        "t2 = torch.tensor([1e-323, 1e-235, 1e-121], dtype=torch.float64)\n",
        "print ('t2: ', t2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t1:  tensor([0.0000, 0.0000, 0.0000])\n",
            "t2:  tensor([9.8813e-324, 1.0000e-235, 1.0000e-121])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}